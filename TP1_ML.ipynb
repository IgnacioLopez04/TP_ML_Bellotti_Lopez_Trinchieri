{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP N° 1: Análisis Exploratorio de Datos\n",
    "## Heart Diseases Dataset\n",
    "Este conjunto de datos es una versión avanzada del clásico conjunto de datos de enfermedades cardíacas de UCI Machine Learning, enriquecido con más características para soportar análisis más sofisticados.\n",
    "\n",
    "## 1- Listado de variables y selección "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import sklearn_pandas\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./heart_disease_data_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "# Muestra las dimensiones del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos por las columnas de interes\n",
    "subset = data.loc[:, ['sex','cp','fbs','restecg','thalach', 'exang','oldpeak','slope', 'ca','thal', 'num','age_group', 'cholesterol_level', 'bp_level','risk_score', 'symptom_severity', 'risk_factor', 'avg_chol_by_age_group']]\n",
    "subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los tipos de datos\n",
    "subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elije 10 filas al azar del DataFrame\n",
    "subset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='thalach', )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando la variable \"thalach\" podemos ver que uno de los registros que tiene es atípico. Este registro va a ser eliminado porque puede perjudicar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subset[subset['thalach'] == 71]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.drop(index=245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='thalach', )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el gráfico en barras podemos deducir que en la mayoria de datos del subconjunto es 0, es decir, que no se detectaron enfermedades. Y luego la cantidad de casos donde se empieza a detectar enfermedades se encuentran escalonadas, yendo desde el 1 (enfermedad leve) hasta 4 (enfermedad grave)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Análisis detallado de un conjunto de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Nulos\n",
    "Estos son los valores nulos encontrados en el subset de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamiento de valores nulos\n",
    "\n",
    "**Variables:**\n",
    "- **ca: numerica**\n",
    "- **thal: numerica**\n",
    "- **age_group: cualitativa**\n",
    "- **cholesterol_level: cualitativa**\n",
    "- **bp_level: cualitativa**\n",
    "- **risk_factor: numerica**\n",
    "- **avg_chol_by_age_group: numerica**\n",
    "\n",
    "Para las variables numericas, el tratamiento que llevaremos a cabo sera rellenar con la media\n",
    "Para las variables cualitativas, el tratamiento será rellenar con el valor que mas se repite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'ca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['ca'] = subset['ca'].fillna(subset['ca'].mean())\n",
    "subset['ca'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'thal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[subset['thal'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['thal'] = subset['thal'].fillna(subset['thal'].mean())\n",
    "subset['thal'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'age_group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['age_group'] = subset['age_group'].fillna(subset['age_group'].mode()[0])\n",
    "subset['age_group'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'cholesterol level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['cholesterol_level'] = subset['cholesterol_level'].fillna(subset['cholesterol_level'].mode()[0])\n",
    "subset['cholesterol_level'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'bp_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['bp_level'] = subset['bp_level'].fillna(subset['bp_level'].mode()[0])\n",
    "subset['bp_level'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'risk_factor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['risk_factor'] = subset['risk_factor'].fillna(subset['risk_factor'].mean())\n",
    "subset['risk_factor'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tratamiento de valores nulos de 'avg_chol_by_age_group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['avg_chol_by_age_group'] = subset['avg_chol_by_age_group'].fillna(subset['avg_chol_by_age_group'].mean())\n",
    "subset['avg_chol_by_age_group'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTO PUEDE JUNTARSE EN DOS CELDAS, UNA CON LAS NUMERICAS Y OTRA CON LAS CUALITATIVAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable de salida\n",
    "**num** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.num.value_counts().plot.bar(title='num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar en el grafico que de la variable **num** se encuentra dividida en los siguientes porcentajes:\n",
    "- **0 - 55,21%**\n",
    "- **1 - 18.51%**\n",
    "- **2 - 11.78%**\n",
    "- **3 - 11.78%**\n",
    "- **4 - 4.37%**\n",
    "\n",
    "Esto nos indica que el 55% de las personas no se detectaron enfermedades cardiacas, y el resto, el 45% indica que hay enfermedad cardiaca entre sus diferentes gravedades. Esto nos muestra que hay una tendencia en la cual mientras más grave sea la enfermedad cardiaca, menor es la cantidad de personas hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = subset['num'].mean()\n",
    "\n",
    "std_dev = subset['num'].std()\n",
    "\n",
    "print(f\"Media: {mean}\")\n",
    "print(f\"Desviación estándar: {std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación de la Media: Es 0.9337, lo que indica que el valor promedio de la variable es cercano a 1. Esto sugiere que la mayoría de los datos están en los valores más bajos (0 y 1), con algunos valores más altos contribuyendo a elevarla ligeramente.\n",
    "\n",
    "Interpretación de la Desviación Estándar: Es 1.229, lo que nos indica cuánto se desvían los datos de la media, en promedio. Es relativamente alta en comparación con la media, lo que sugiere que hay una considerable variabilidad en los datos con una distribución sesgada hacia los valores más bajos (cercanos a 0). Esto es consistente con una distribución en la que hay pocos datos con valores altos (3 o 4), lo cual tiene sentido, dado que es más complejo tener mayor cantidad de registros de pacientes con mayor gravedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar de una manera mas entendible en el trabajo decidimos renombrar las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETTER_COLUMN_NAMES = {\n",
    "    'sex': 'sex',\n",
    "    'cp': 'chest_pain',\n",
    "    'fbs':'fasting_blood_sugar',\n",
    "    'restecg':'rest_ecg',\n",
    "    'thalach':'max_heart_rate',\n",
    "    'exang':'exercise_induced_angina',\n",
    "    'oldpeak':'depression_induced_ex',\n",
    "    'slope':'slope',\n",
    "    'ca':'vessels_colored_fl',\n",
    "    'thal':'thalassemia',\n",
    "    'num':'diagnosis',\n",
    "    'age_group':'age_group',\n",
    "    'cholesterol_level':'cholesterol_level',\n",
    "    'bp_level':'blood_pressure_level',\n",
    "    'risk_score':'risk_score',\n",
    "    'symptom_severity':'symptom_severity',\n",
    "    'risk_factor':'risk_factor',\n",
    "    'avg_chol_by_age_group':'avg_chol_by_age_group'\n",
    "}\n",
    "\n",
    "subset.rename(columns=BETTER_COLUMN_NAMES, inplace=True)\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la comprensión de las proporciones de las variables en estudio en función de diagnosis, realizamos una funcion que nos permite obtener las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_proporcion_por_valor(df, variable1, valor1, variable2, valor2):\n",
    "    filtro = (df[variable1] == valor1) & (df[variable2] == valor2)\n",
    "    conteo_filtro = df[filtro].shape[0]\n",
    "\n",
    "    proporcion = conteo_filtro / df[variable2].value_counts()[valor2]\n",
    "    \n",
    "    return proporcion\n",
    "\n",
    "def mostrar_total_propociones(variable1, variable2):\n",
    "    proporciones = {}\n",
    "    valores_diagnosis = subset[variable1].unique()\n",
    "    valores_vessels_colored_fl = subset[variable2].unique()\n",
    "\n",
    "    for valor_diagnosis in valores_diagnosis:\n",
    "        for valor_vessels in valores_vessels_colored_fl:\n",
    "            proporcion = calcular_proporcion_por_valor(subset, variable1, valor_diagnosis, variable2, valor_vessels)\n",
    "            proporciones[(valor_diagnosis, valor_vessels)] = proporcion\n",
    "\n",
    "    proporciones_df = pd.DataFrame(list(proporciones.items()), columns=['Combinación', 'Proporción'])\n",
    "    proporciones_df[variable2] = proporciones_df['Combinación'].apply(lambda x: x[1])\n",
    "    proporciones_df[variable1] = proporciones_df['Combinación'].apply(lambda x: x[0])\n",
    "    proporciones_df = proporciones_df.drop(columns=['Combinación'])\n",
    "\n",
    "    print(proporciones_df.sort_values(by=[variable2, variable1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.sex.value_counts().plot.bar(title='Sex (1: Hombre 0: Mujer)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'sex']).size().unstack(fill_value=0)\n",
    "grouped_data.plot(kind='bar', title='Distribución de sex por diagnosis')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que considerar que los registros de sex se encuentra desbalaceados, siendo la cantidad de hombres en los registros de un 69.02% y de las mujeres el 32.65%, por lo que es evidente que el gráfico indique que los hombres son más propensos a contraer una enfermedad cardiaca. \n",
    "\n",
    "Para realizar un mejor análisis, sacamos la porporción de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las mujeres, la mayoría no presenta enfermedad cardíaca (Diagnóstico 0) y la proporción disminuye considerablemente para diagnósticos más graves.\n",
    "Entre los hombres, también hay una alta proporción sin enfermedad cardíaca, pero la distribución es más equitativa entre las diferentes categorías de severidad comparado con las mujeres.\n",
    "Esto sugiere que, en el grupo representado, tanto hombres como mujeres tienen una alta proporción sin enfermedad cardíaca, pero los hombres tienen una mayor proporción en las categorías de diagnóstico más severas en comparación con las mujeres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Depression_induced_ex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='depression_induced_ex')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable representa la depresión inducida por el ejercicio en relación al reposo, lo que quiere decir que cuanto mas cercano a 0 es mejor, dado que un corazón saludable no debería esforzarse demasiado para hacer ejercicio.\n",
    "\n",
    "Podemos observar en el gráfico que, el 50% de los datos se encuentran entre 0 y 1,6. A su vez, observamos que hay 4 registros con valores aberrantes, los cuales contemplaremos, dado que debemos analizar qué tan grave es la enfermedad cardíaca de un paciente, y estos casos aislados pueden darle información relevante al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.boxplot(column='depression_induced_ex', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de depression_induced_ex por diagnosis')\n",
    "plt.suptitle('')  \n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('depression_induced_ex')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estadísticas muestran que la depresión inducida por el ejercicio aumenta a medida que el grupo de diagnóstico sube de 0 a 4. Los grupos con diagnósticos más altos (3 y 4) tienen valores promedio y desviaciones estándar más altos, indicando una mayor intensidad y variabilidad de la depresión inducida. En contraste, los grupos con diagnósticos más bajos (0 y 1) muestran menor intensidad y dispersión. Por lo tanto, hay una relación directamente proporcional entre el diagnóstico y la depresión inducida, con mayor severidad y variabilidad en los diagnósticos más altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grupo Etáreo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.age_group.value_counts().plot.bar(title='Grupo etario', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'age_group']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de age_group por num')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.age_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista observamos que el grupo etáreo de los **50s** es aquel que más destaca entre los diferentes valores de diagnosis, al igual que aquel grupo que se encuentra entre los **60s**.\n",
    "\n",
    "**Porcentajes**\n",
    "- **30s - 4.71%**\n",
    "- **40s - 24.24%**\n",
    "- **50s - 41.07%**\n",
    "- **60s - 26.59%**\n",
    "- **70s - 3.36%**\n",
    "\n",
    "Con estos porcentajes observamos que los registros de las edades etarias se encuentra desbalanceados, siendo el grupo etáreo de 50s con el mayor porcentaje. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer un análisis más profundo, sacamos la proporción de cada grupo etáreo en funcion con la gravedad de la enfermedad:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'age_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución muestra que la gravedad de la enfermedad aumenta con la edad, especialmente a partir de los 50 años, donde se observa un mayor porcentaje de casos en niveles de gravedad moderada y severa. Los grupos más jóvenes (30s y 40s) presentan una mayoría de casos leves o sin enfermedad, mientras que en los grupos mayores (60s y 70s) se ve una mayor dispersión, con algunos individuos en niveles graves, especialmente en los 70s, donde un 20% alcanza el nivel más alto de severidad. Esto sugiere una relación clara entre la edad y la progresión de la enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CP - Tipo de dolor de pecho**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es especialmente relevante en un contexto cardíaco, ya que el dolor en el pecho suele estar relacionado con el corazón. Esta clasificación es crucial para evaluar y diferenciar entre diferentes presentaciones clínicas que podrían indicar la presencia o ausencia de una condición cardíaca. \n",
    "\n",
    "Valores que puede tomar:\n",
    "\n",
    "- 1: Angina típica -- suele estar relacionada con problemas coronarios significativos, por lo que es grave.\n",
    "\n",
    "- 2: Angina atípica -- puede retrasar el tratamiento dado que es díficl de analizar, aunque en algunos casos puede no ser tan grave como la angina típica.\n",
    "\n",
    "- 3: Dolor no anginal -- este tipo de dolor no suele estar relacionado con el corazón, lo que lo hace menos grave desde el punto de vista cardíaco.\n",
    "\n",
    "- 4: Asintomático -- al no haber dolor ni otras señales de advertencia, el problema puede pasar desapercibido y no tratarse a tiempo, lo que aumenta el riesgo de complicaciones como infartos en pacientes que estan enfermos. Pero también aquellos que estén sanos entran en esta categoría.\n",
    "\n",
    "Según lo investigado, el asíntomatico puede ser bueno o muy grave, dado que no asegura que una persona no está enferma, ya que puede desarrollarse una enfermedad cardíaca sin presentar síntomas. \n",
    "\n",
    "La pregunta que haríamos es: ¿cómo tomamos los registros asintomáticos, cómo algo bueno o malo? Es decir, ¿cuánto mayor es el valor de estos resultados, menos probabilidades de tener una enfermedad grave? ¿O están desordenados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.chest_pain.value_counts().plot.bar(title='Tipo de dolor de pecho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'chest_pain']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de chest_pain por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.chest_pain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar el tipo de dolor de pecho es una variable relevante para determinar la gravedad de la enfermedad cardíaca. \n",
    "\n",
    "Pero, también se ve en el gráfico que aquellos pacientes asintomáticos (4) se encuentran distribuidos uniformemente entre todas las variables del diagnosis por lo cual, creemos que distorisionará las predicciones del modelo dado que hay tanto casos de reigstros asintomáticos que no presentan ninguna gravedad, como también hay casos que presentan las diferentes gravedades. \n",
    "\n",
    "**Porcentaje de chest_pain**\n",
    "- **4 - 46.80%**\n",
    "- **3 - 28.95%**\n",
    "- **2 - 16.83%**\n",
    "- **1 - 7.40%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'chest_pain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FBS - Azúcar en sangre en ayunas > 120 mg/dl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.fasting_blood_sugar.value_counts().plot.bar(title='Azúcar en sangre > 120ml/dl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'fasting_blood_sugar']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de fasting_blood_sugar por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.fasting_blood_sugar.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores de fasting_blood_sugar\n",
    "- 0: No supera de 120 mg/dl de azúcar en sangre.\n",
    "- 1: Supera de 120 mg/dl de azúcar en sangre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'fasting_blood_sugar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grupo con fasting_blood_sugar mayor de 120 mg/dl tiende a tener una mayor proporción de casos con diagnosis 2 y 3, lo que sugiere que altos niveles de azúcar en sangre están correlacionados con una mayor gravedad de la enfermedad cardíaca, aunque no necesariamente en los casos más críticos (diagnosis 4). Esto respalda la relación conocida entre la hiperglucemia y el riesgo de complicaciones cardíacas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **restecg - Resultado electrocardiográfico en reposo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.rest_ecg.value_counts().plot.bar(title='rest_ecg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'rest_ecg']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de rest_ecg por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('rest_ecg')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'rest_ecg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valores**\n",
    "\n",
    "- 0 (Normal): Sin problemas evidentes.\n",
    "- 1 (ST-T anomalía): Podría indicar problemas de oxigenación del corazón o daño en el músculo cardíaco.\n",
    "- 2 (Hipertrofia ventricular izquierda): Señala un posible agrandamiento del ventrículo izquierdo, generalmente relacionado con presión arterial alta y asociado a mayor riesgo de enfermedad cardíaca.\n",
    "\n",
    "En resumen, los resultados electrocardiográficos en reposo parecen estar asociados con la severidad de la enfermedad cardíaca de manera variable. Un electrocardiograma normal se asocia predominantemente con la ausencia de enfermedad, mientras que resultados que muestran hipertrofia ventricular o anomalías en ST-T están más uniformemente distribuidos entre las diferentes severidades de la enfermedad, sugiriendo una relación más compleja entre los resultados en reposo y la severidad de la enfermedad cardíaca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **exang - angina inducida por el ejercicio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Indica un flujo sanguíneo insuficiente al corazón durante el esfuerzo, señal de enfermedad coronaria.; 1: si, 0: no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.exercise_induced_angina.value_counts().plot.bar(title='exang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'exercise_induced_angina']).size().unstack(fill_value=0)\n",
    "grapf = grouped_data.plot(kind='bar', title='Distribución de exercise_induced_angina por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'exercise_induced_angina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos muestran que la presencia de angina inducida por ejercicio está asociada con una gama más amplia de severidad en la enfermedad cardíaca, ya que los pacientes con flujo sanguíneo insuficiente durante el ejercicio tienen una distribución variada entre diferentes niveles de severidad. En contraste, aquellos sin angina inducida por ejercicio tienden a concentrarse en los niveles menos severos de la enfermedad, lo que indica que la angina inducida puede estar relacionada con una mayor severidad de la enfermedad cardíaca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **slope**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es la pendiente del segmento ST en el pico de ejercicio. Si es ascendente (valor 1) es el valor menos procupante a la hora de tener que indicar alguna enfermedad cardiaca, por lo contrario, el valor 3 si es preocupante porque indica que la pendiente es descendente, y el valor 2 es plano, lo cual es ligeramente preocupante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.slope.value_counts().plot.bar(title='slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'slope']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de slope por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('slope')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'slope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos muestran que una pendiente normal del segmento ST (slope = 1) en el ejercicio se asocia con niveles menos severos de enfermedad cardíaca, mientras que una pendiente preocupante (slope = 3) está vinculada a una mayor severidad de la enfermedad. Una pendiente incierta (slope = 2) tiene una distribución más variada entre los diagnósticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vessels colored fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.vessels_colored_fl.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca tenemos un problema, el tipo de variable de 'vessels_colored_fl' es float, pero los datos adentro son todos enteros, asi que seran transformados en int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['vessels_colored_fl'] = subset['vessels_colored_fl'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.vessels_colored_fl.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'vessels_colored_fl']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de vessels_colored_fl por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'vessels_colored_fl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el número de vasos principales coloreados por fluroscopia, reflejando la cantidad de vasos afectados y la severidad de la obstruccion. Como podemos ver, aquellos que no poseen enfermedad cardiaca, son aquellos que no poseen vasos principales bloqueados.\n",
    "\n",
    "Para aclarar, la escala de 0 a 4 generalmente tiene el siguiente significado:\n",
    "\n",
    "0: No hay vasos principales afectados; es decir, no se observa enfermedad coronaria significativa. 1: Un vaso principal está afectado. 2: Dos vasos principales están afectados. 3: Tres vasos principales están afectados.\n",
    "\n",
    "EN conclusión, a medida que aumenta la cantidad de vasos afectados, aumenta la gravedad de la enfermedad cardiaca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Thalassemia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de \"thalassemia\" son enteros, solo que en el dataframe se encuentran almacenados como float, entonces a la hora de realizar el gráfico aparecen un par de errores. Para solucionar este problema, vamos a pasarlos a enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[\"thalassemia\"] = subset[\"thalassemia\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'thalassemia']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de thalassemia por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'thalassemia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos presenta proporciones que muestran cómo se distribuye la variable thalassemia entre diferentes valores de diagnóstico (diagnosis). Por ejemplo, para el valor de diagnóstico 3, la proporción de thalassemia varía desde 0.781818, indicando que aproximadamente el 78.18% de las observaciones tienen un valor específico de thalassemia, hasta 0.012121, donde solo el 1.21% de las observaciones presentan un valor diferente. De manera similar, para el diagnóstico 4, la proporción de thalassemia alcanza el 50% para algunos valores, sugiriendo una distribución equitativa en estas observaciones. Estas proporciones permiten observar cómo cambia la frecuencia de thalassemia en relación con los diferentes diagnósticos, lo que puede ser útil para identificar patrones en la prevalencia de thalassemia asociada a cada diagnóstico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Max_heart_rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frecuencia cardiaca máxima alcanzada (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.boxplot(column='max_heart_rate', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de max_heart_rate por diagnosis')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('thalassemia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo un análisis de los diagramas de caja en cada valor de la gravedad, llegamos a la conclusión de que el valor de la mediana es inversamente proporiconal a la gravedad de la enfermedad cardíaca. Esto indica que, a mayor gravedad de la enfermedad, menor es la frecuencia cardíaca máxima alcanzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cholesterol_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.cholesterol_level.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'cholesterol_level']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de cholesterol_level por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'cholesterol_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de las proporciones de niveles de colesterol según el diagnóstico muestra que los niveles de colesterol normal predominan en los diagnósticos menos graves, mientras que los niveles altos y bajos se distribuyen de manera más variada en diagnósticos más severos. A medida que la severidad del diagnóstico aumenta, las proporciones de colesterol alto y bajo tienden a cambiar, sugiriendo que los niveles de colesterol están relacionados con la severidad de la enfermedad, aunque esta relación no es estrictamente lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blood_pressure_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = subset.groupby(['diagnosis', 'blood_pressure_level']).size().unstack(fill_value=0)\n",
    "graph = grouped_data.plot(kind='bar', title='Distribución de blood_pressure_level por diagnosis')\n",
    "\n",
    "for container in graph.containers:\n",
    "    graph.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_total_propociones('diagnosis', 'blood_pressure_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos muestra la proporción de niveles de colesterol (cholesterol_level) en relación con diferentes valores de diagnóstico (diagnosis). Para el diagnóstico 0, la proporción de personas con colesterol normal es alta, alcanzando 0.630000, mientras que las proporciones para los niveles high y low son más bajas, con 0.477124 y 0.571429 respectivamente. A medida que cambia el diagnóstico, las proporciones también cambian: por ejemplo, para el diagnóstico 1, la proporción para colesterol high es 0.215686, mientras que para low es 0.142857 y para normal es 0.150000. Estas proporciones permiten observar cómo varía la distribución del colesterol en función del diagnóstico, proporcionando una visión de la relación entre los niveles de colesterol y la condición diagnosticada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='risk_score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bxp = subset.boxplot(column='risk_score', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de risk_score por diagnosis')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('risk_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='risk_factor')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bxp = subset.boxplot(column='risk_factor', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de risk_factor por diagnosis')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('risk_factor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symptom_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='symptom_severity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bxp = subset.boxplot(column='symptom_severity', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de symptom_severity por diagnosis')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('symptom_severity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg_chol_by_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(subset, y='avg_chol_by_age_group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bxp = subset.boxplot(column='avg_chol_by_age_group', by='diagnosis', grid=False)\n",
    "\n",
    "plt.title('Distribución de avg_chol_by_age_group por diagnosis')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('diagnosis')\n",
    "plt.ylabel('avg_chol_by_age_group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_unicos_age_group = subset['age_group'].unique()\n",
    "vu_chol =  subset['cholesterol_level'].unique()\n",
    "vu_bp = subset['blood_pressure_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[\"age_group\"] = subset.age_group.replace(valor_unicos_age_group, [60, 30, 40, 50, 70])\n",
    "subset['cholesterol_level'] = subset.cholesterol_level.replace(vu_chol, [1, 2, 0])\n",
    "subset['blood_pressure_level'] = subset.blood_pressure_level.replace(vu_bp, [2,0,1])\n",
    "sns.heatmap(subset.corr(), annot=True, cmap='RdYlGn', linewidths=0.2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Menor relacion con diagnosis**\n",
    "1. **Max_heart_rate** tiene una baja correlacion con **diagnosis**, que es nuestra variable de salida. Esto nos lleva a entender que max_heart_rate no afecta a la hora de determinar el diagnostico. Además podemos ver que **Max_heart_rate** tiene una baja relación con el resto de variables por lo que nos lleva a pensar de que se pueda eleminar del dataset. \n",
    "\n",
    "**Estas son las variables con mayor correlacion con diagnosis**\n",
    "Consideramos que empieza haber cierta correlacion a partir de 0.40.\n",
    "\n",
    "1. **chest_pain** 0.4\n",
    "2. **exercise_induced_angina** 0.44\n",
    "3. **depression_induced_ex** 0.43\n",
    "4. **vessel_coloured_fl** 0.46\n",
    "5. **thalassemia** 0.53\n",
    "6. **symptom_severity** 0.49\n",
    "7. **risk_factor** 0.54\n",
    "\n",
    "**Una vez identificadas estas variables, queremos saber con que otras variables poseen una mayor correlación aparte de diagnosis**\n",
    "1. **chest_pain**\n",
    "- risk_factor - 0.42\n",
    "- symptom_severity - 0.42\n",
    "\n",
    "2. **exercise_induced_angina**\n",
    "- risk_factor - 0.41\n",
    "\n",
    "3. **depression_induced_ex**\n",
    "- slope - 0.54\n",
    "- symptom_severity - 0.94\n",
    "- risk_factor - 0.84\n",
    "\n",
    "5. **thalassemia**\n",
    "- risk_factor - 0.54\n",
    "\n",
    "6. **symptom_severity**\n",
    "- risk_factor - 0.93\n",
    "- slope - 0.51\n",
    "- depression_induced_ex - 0.94\n",
    "- chest_pain - 0.42\n",
    "\n",
    "7. **risk_factor**\n",
    "- symptom_severity - 0.93\n",
    "- chest_pain - 0.42\n",
    "- exercise_induced_angina - 0.41\n",
    "- depression_induced_ex - 0.84\n",
    "- thalassemia - 0.54\n",
    "\n",
    "Para el resto de variables que no muestran algun signo de generar una alta influencia en diagnosis, se van a probar con eliminarlas del dataset y evaluar si influye considerablemente en el resultado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listado de posibles dudas/preguntas al encargado de proveer los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Que tan fiable son los datos?\n",
    "2. ¿Por qué hay tantos outliners en las siguientes variables risk_score, risk_factor, symptom_severity y avg_chol_by_age_group? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Hipótesis sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def preparar_datos_para_info_mutua(subset, target_column):\n",
    "    subset_encoded = subset.copy()\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    for column in subset_encoded.columns:\n",
    "        if subset_encoded[column].dtype == 'object':\n",
    "            subset_encoded[column] = le.fit_transform(subset_encoded[column])\n",
    "    \n",
    "    return subset_encoded\n",
    "\n",
    "def calcular_informacion_mutua(subset, target_column):\n",
    "    subset_encoded = preparar_datos_para_info_mutua(subset, target_column)\n",
    "    \n",
    "    X = subset_encoded.drop(columns=[target_column])\n",
    "    y = subset_encoded[target_column]\n",
    "    \n",
    "    info_mutua = mutual_info_classif(X, y, discrete_features='auto')\n",
    "    \n",
    "    info_mutua_df = pd.DataFrame({\n",
    "        'Variable': X.columns,\n",
    "        'Informacion_Mutua': info_mutua\n",
    "    })\n",
    "    \n",
    "    info_mutua_df = info_mutua_df.sort_values(by='Informacion_Mutua', ascending=False)\n",
    "    \n",
    "    return info_mutua_df\n",
    "\n",
    "resultado_info_mutua = calcular_informacion_mutua(subset, 'diagnosis')\n",
    "print(resultado_info_mutua)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Formulación de hipótesis sobre la variable target bajo determinadas condiciones\n",
    "\n",
    "1. En la variable **chest_pain** se piensa que esta puede no influir a la hora de predecir si hay o no alguna enfermedad cardiaca.\n",
    "2. En la variable **fasting_blood_sugar** se piensa que puede no influir a la hora de predecir si hay o no alguna enfermedad cardiaca. No se termina de saber si al ser true nos asegure que pueda haber algun tipo de enfemerdad cardiaca. \n",
    "3. Planteamos que las variables mencionadas como aquellas con mayor relación son las que más van a influir con el resultado final de diagnosis y a su vez, cada una de estas variables estan relacionadas con otras variables que se consideraran importantes a la hora de obtener el diagnosis.\n",
    "4. **Max_heart_rate** no tiene una correlación con diagnosis, por lo que esta variable no tiene importancia para diagnosis.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Comprobación de la hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Creación de nuevas variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primera instancia, lo que vamos a hacer es elegir cuál será la métrica de performance que utilicemos para evaluar el modelo.\n",
    "Las métricas disponibles para elegir son **Accuracy, Precision, ReCall y F1-Score**. Pero, antes de elegir una, tendremos que\n",
    "evaluar que tan importante es nuestro resultado.\n",
    "\n",
    "Para eso primero nos haremos unas preguntas:\n",
    "- ¿Que tan importante es que cuando nosotros digamos A, sea realmente A y no un falso posito?\n",
    "- ¿Que tan importante es que cuando nosotros digamos que no es A, realmente sea A y no un falso negativo?\n",
    "- ¿Que tan costo sería errar en la predición?\n",
    "\n",
    "*Nota del facha que lo escribío*: Lo que me refiero es hacer preguntas y ver que tan seguro queremos que nuestro modelo este para decir si\n",
    "tiene una enfermedad o no. Obviamente queremos que este bastante seguro. Si el modelo dice que no esta enfermo, pero en realidad lo esta,\n",
    "no es un resultado que nosotros queramos. Ahora, si el modelo dice que esta enfermo, pero en realidad no lo esta, o dice que tiene un enfermedad tipo 4 y en realidad es tipo 2, tampoco es taaan grave. Ustedes que tienen mas idea les va a salir de die y seguro me entienden\n",
    "\n",
    "Una vez respondidas esas preguntas, podemos decir que la métrica elegida es: **Inserte métrica fachera como F1-Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora como siguiente paso vamos a implementar **feature engineering**, si es posible, para mejorar los datos de entrada de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el conjunto de datos en train, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, not_train = train_test_split(subset, test_size=0.4, random_state=42)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=42)\n",
    "\n",
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos nuestro mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (['sex'], [LabelBinarizer()]),\n",
    "    (['chest_pain'], [StandardScaler()]),\n",
    "    (['fasting_blood_sugar'], [OneHotEncoder()]),\n",
    "    (['rest_ecg'], [StandardScaler()]),\n",
    "    (['max_heart_rate'], [StandardScaler()]),\n",
    "    (['exercise_induced_angina'], [OneHotEncoder()]),\n",
    "    (['depression_induced_ex'], [StandardScaler()]),\n",
    "    (['slope'], [StandardScaler()]),\n",
    "    (['vessels_colored_fl'], [StandardScaler()]),\n",
    "    (['thalassemia'], [StandardScaler()]),\n",
    "    (['age_group'], [OneHotEncoder()]),\n",
    "    (['cholesterol_level'], [OneHotEncoder()]),\n",
    "    (['blood_pressure_level'], [OneHotEncoder()]),\n",
    "    (['risk_score'], [StandardScaler()]),\n",
    "    (['symptom_severity'], [StandardScaler()]),\n",
    "    (['risk_factor'], [StandardScaler()]),\n",
    "    (['avg_chol_by_age_group'], [StandardScaler()])\n",
    "])\n",
    "\n",
    "mapper.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como realiza las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.sample(1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.transform(subset.sample(1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.transformed_names_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos el Pipeline\n",
    "Se van a generar los Pipelines de los 3 modelos elegidos, estos son:\n",
    "- LogisticRegression\n",
    "- k-NN\n",
    "- Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def evaluate_model(model, set_names=('train', 'validation'), title=''):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],        \n",
    "    }\n",
    "        \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train', 'validation', 'test']\n",
    "        set_data = globals()[set_name]  # <- hack feo...\n",
    "    \n",
    "        y = set_data.diagnosis\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Accuracy'].append(metrics.accuracy_score(y, y_pred))\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred, average='macro'))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred, average='macro'))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred, average='macro'))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos una exploración de hyperparámetros mediante una búsqueda en grilla para determinar que combinación de hyperparámetros es la más\n",
    "adecuada para este tipo de problemas.\n",
    "\n",
    "Los hyperparámetros a explorar son:\n",
    "1. **`penalty`**:  \n",
    "   Define el tipo de regularización que se aplicará para evitar el sobreajuste del modelo. Las opciones son:\n",
    "   - `'l1'`: Lasso, aplica una regularización L1, lo que puede llevar a coeficientes exactamente cero (selección de características).\n",
    "   - `'l2'`: Ridge, aplica una regularización L2, penaliza grandes coeficientes pero no los reduce a cero.\n",
    "   - `'elasticnet'`: Combinación de normativas L1 y L2 (solo con `solver='saga'`).\n",
    "\n",
    "2. **`C`**:  \n",
    "   Es el inverso de la fuerza de regularización. Controla cuánto penalizará el modelo los coeficientes grandes.  \n",
    "   - Valores pequeños de `C` aumentan la regularización (más simple).\n",
    "   - Valores grandes de `C` disminuyen la regularización (más ajuste).  \n",
    "   - Valores típicos: `[0.001, 0.01, 0.1, 1, 10, 100]`.\n",
    "\n",
    "3. **`solver`**:  \n",
    "   Algoritmo utilizado para optimizar los coeficientes del modelo. Las opciones son:\n",
    "   - `'liblinear'`: Eficiente para problemas pequeños o clasificación binaria, utiliza descenso coordinado.\n",
    "   - `'newton-cg'`: Basado en gradiente, adecuado para problemas multiclase.\n",
    "   - `'lbfgs'`: Quasi-Newton, rápido y adecuado para problemas multiclase.\n",
    "   - `'sag'`: Gradiente estocástico promedio, eficiente para grandes conjuntos de datos.\n",
    "   - `'saga'`: Similar a `'sag'`, pero soporta regularización L1 y problemas grandes.\n",
    "\n",
    "4. **`max_iter`**:  \n",
    "   Número máximo de iteraciones para que el algoritmo alcance la convergencia. Aumentar este valor puede ser útil si el modelo no está convergiendo.  \n",
    "   - Valores típicos: `[100, 200, 300]`.\n",
    "\n",
    "5. **`tol`**:  \n",
    "   Tolerancia para la convergencia. Define el criterio para detener el ajuste cuando el cambio en la función objetivo es menor que `tol`.  \n",
    "   - Valores bajos hacen el modelo más preciso, pero toman más tiempo.  \n",
    "   - Valores típicos: `[1e-4, 1e-3, 1e-2]`.\n",
    "\n",
    "6. **`class_weight`**:  \n",
    "   Ajusta los pesos de las clases para manejar desbalanceos en los datos:\n",
    "   - `None`: Todas las clases tienen el mismo peso.\n",
    "   - `'balanced'`: Ajusta automáticamente los pesos en función de la distribución de clases, dando más peso a las clases minoritarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "LR_clf = LogisticRegression(random_state=42)\n",
    "LR_params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['newton-cg', 'liblinear', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter': [100, 300, 500, 1000],\n",
    "    'tol': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(LR_clf, LR_params, refit=True, verbose=1)\n",
    "\n",
    "pipeLR = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "pipeLR.fit(train, train.diagnosis)\n",
    "\n",
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en los resultados de la búsqueda en grilla, la mejor combinación de parámetros es:\n",
    "- 'C': 0.001\n",
    "- 'class_weight': None\n",
    "- 'max_iter': 100\n",
    "- 'penalty': 'l2'\n",
    "- 'solver': 'liblinear'\n",
    "- 'tol': 0.0001\n",
    "\n",
    "Dando como mejor resultado: **0.6298798798798798**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, generamos un modelo con los mejores parámetros y realizamos la predicción\n",
    "*Nota del facha que escribe*: Nose si hace falta hacer ooootro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best_params = {'C': 0.001,\n",
    "  'class_weight': None, # por defecto\n",
    "  'max_iter': 300, # por defecto\n",
    "  'penalty': 'l2', # por defecto\n",
    "  'solver': 'liblinear',\n",
    "  'tol': 0.0001} # por defecto\n",
    "\n",
    "LR_clf_best_params = LogisticRegression(random_state=42,\n",
    "                                        solver='liblinear',\n",
    "                                        C=0.1\n",
    "                                        )\n",
    "\n",
    "pipeLR = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', LR_clf_best_params),\n",
    "])\n",
    "\n",
    "pipeLR.fit(train, train.diagnosis)\n",
    "\n",
    "y_predLR = pipeLR.predict(validation)\n",
    "y_predLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos las métricas elegidas.\n",
    "\n",
    "Aca evalúa todas qsya no conozco otra jasjsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(pipeLR, title='LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN\n",
    "Haremos una exploración de hyperparámetros mediante una búsqueda en grilla para determinar que combinación de hyperparámetros es la más\n",
    "adecuada para este tipo de problemas.\n",
    "\n",
    "Los hyperparámetros a explorar son:\n",
    "1. **`n_neighbors`**: El número de vecinos a considerar. Ejemplos de valores a probar:\n",
    "   - `[3, 5, 7, 10]`\n",
    "\n",
    "2. **`weights`**: La función de peso para los vecinos. Opciones disponibles:\n",
    "   - `'uniform'` (todos los vecinos tienen el mismo peso)\n",
    "   - `'distance'` (los vecinos más cercanos tienen más peso)\n",
    "\n",
    "3. **`algorithm`**: El algoritmo para calcular los vecinos. Opciones disponibles:\n",
    "   - `'auto'`\n",
    "   - `'ball_tree'`\n",
    "   - `'kd_tree'`\n",
    "   - `'brute'`\n",
    "\n",
    "4. **`p`**: La potencia del parámetro de la métrica de distancia. Ejemplos de valores a probar:\n",
    "   - `1` (distancia de Manhattan)\n",
    "   - `2` (distancia Euclidiana)\n",
    "\n",
    "5. **`leaf_size`**: Tamaño de la hoja para el algoritmo `'ball_tree'` o `'kd_tree'`. Ejemplos de valores a probar:\n",
    "   - `[10, 20, 30]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_params = [{\n",
    "    'n_neighbors': np.linspace(1, 100, 100, dtype=int)\n",
    "}]\n",
    "\n",
    "clf = GridSearchCV(knn_clf, knn_params, refit=True, verbose=1)\n",
    "\n",
    "gs_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "gs_pipe.fit(train, train.diagnosis)\n",
    "\n",
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada la búsqueda en grilla, podemos ver que los mejores hyperparámetros son:\n",
    "- 'algorithm': 'auto'\n",
    "- 'leaf_size': 5\n",
    "- 'n_neighbors': 7\n",
    "- 'p': 1\n",
    "- 'weights': 'distance'\n",
    "\n",
    "Dando como mejor resultado: **0.6573573573573575**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN_best_params = {\n",
    "#   'algorithm': 'auto', # default\n",
    "#   'leaf_size': 5,\n",
    "#   'n_neighbors': 7,\n",
    "#   'p': 1,\n",
    "#   'weights': 'distance',\n",
    "# }\n",
    "\n",
    "# kNN_clf_best_params = KNeighborsClassifier(algorithm='auto',\n",
    "#                             p=1,\n",
    "#                             n_neighbors=7,\n",
    "#                             weights= 'distance',\n",
    "#                             leaf_size=5\n",
    "#                             )\n",
    "kNN_clf_best_params = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "pipekNN = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', kNN_clf_best_params),\n",
    "])\n",
    "\n",
    "pipekNN.fit(train, train.diagnosis)\n",
    "\n",
    "y_predkNN = pipekNN.predict(validation)\n",
    "y_predkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(pipekNN, title='kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_clf = DecisionTreeClassifier(random_state=42)\n",
    "TM_params = {\n",
    "  'max_depth': [None, 1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(TM_clf, TM_params, refit=True, verbose=1)\n",
    "\n",
    "TM_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "TM_pipe.fit(train, train.diagnosis)\n",
    "\n",
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_clf = DecisionTreeClassifier(random_state=42, max_depth=2)\n",
    "\n",
    "TM_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', TM_clf),\n",
    "])\n",
    "\n",
    "TM_pipe.fit(train, train.diagnosis)\n",
    "\n",
    "evaluate_model(TM_pipe, title='Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "RF_clf = RandomForestClassifier(random_state=42)\n",
    "RF_params = [{ \n",
    "  'n_estimators': [100, 200, 300, 400], \n",
    "  'max_depth': [None, 1 , 2, 3, 4, 5, 6, 7, 8],\n",
    "  # 'max_features': [2, 5]\n",
    "}]\n",
    "\n",
    "clf = GridSearchCV(RF_clf, RF_params, refit=True, verbose=1)\n",
    "\n",
    "RF_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "RF_pipe.fit(train, train.diagnosis)\n",
    "\n",
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_clf = RandomForestClassifier(random_state=42,\n",
    "                                max_depth=None,\n",
    "                                n_estimators=500,\n",
    "                                max_features=5\n",
    "                                )\n",
    "\n",
    "RF_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('classifier', RF_clf),\n",
    "])\n",
    "\n",
    "RF_pipe.fit(train, train.diagnosis)\n",
    "\n",
    "evaluate_model(RF_pipe, title='Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset['diagnosis'] = subset['diagnosis'].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "# subset.diagnosis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
